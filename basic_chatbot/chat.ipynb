{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "179cd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "444c88cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "class ChatState(TypedDict):\n",
    "    \n",
    "    messages: Annotated[list[BaseMessage], add_messages] # basemessage is a flexible message\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c539975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define llm\n",
    "llm = ChatOllama(model='gemma3:4b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7c52ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState):\n",
    "    \n",
    "    #take user query from state\n",
    "    messages = state['messages']\n",
    "    #send to llm\n",
    "    response = llm.invoke(messages)\n",
    "    #response store state\n",
    "    return {'messages':[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6d1f16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x222a3d09fd0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = MemorySaver()\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "#add nodes\n",
    "graph.add_node('chat_node', chat_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "059ed212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x222a3d09fd0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add edges\n",
    "graph.add_edge(START, 'chat_node')\n",
    "graph.add_edge('chat_node', END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a81098f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90b137a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000222A44556D0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffd61a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hi\n",
      "AI Hi there! How can I help you today? üòä \n",
      "\n",
      "Do you want to:\n",
      "\n",
      "*   Chat about something?\n",
      "*   Ask me a question?\n",
      "*   Play a game?\n",
      "*   Get some information?\n",
      "\n",
      "Just let me know what you're thinking!\n",
      "User: can you tell me about gpt 5\n",
      "AI Okay, let's talk about GPT-5! It's a fascinating and, as of right now, still largely *anticipated* topic. Here's what we know, what's being speculated, and the key differences from its predecessors:\n",
      "\n",
      "**What We Know (Officially Announced - as of November 2, 2023):**\n",
      "\n",
      "* **It's Coming (Eventually):** OpenAI has announced that GPT-5 is in development, but they haven‚Äôt given a firm release date. They've stated they plan to release it sometime in **2024**.\n",
      "* **Significant Improvements:**  They‚Äôve explicitly stated that GPT-5 will represent a \"major step up\" from GPT-4 in terms of capabilities and performance.\n",
      "* **Multimodal Capabilities ‚Äì A HUGE Change:** This is the most significant announced advancement. GPT-5 will be *truly multimodal*, meaning it will be able to seamlessly process and generate content across *multiple* modalities ‚Äì not just text. This includes:\n",
      "    * **Images:** GPT-5 will be able to understand and generate images based on text prompts.\n",
      "    * **Audio:**  It's expected to handle audio input and output, potentially for tasks like transcription, speech generation, and even understanding musical nuances.\n",
      "    * **Video:** While less certain, there's a strong expectation that GPT-5 will be able to process and generate video content.\n",
      "* **Enhanced Reasoning & Problem-Solving:** OpenAI aims for GPT-5 to demonstrate superior reasoning abilities, going beyond just pattern recognition to genuinely understand and solve complex problems.\n",
      "* **Increased Context Window:** Like GPT-4, GPT-5 is expected to have a much larger context window, allowing it to remember and utilize more information from previous parts of a conversation or document.\n",
      "\n",
      "\n",
      "\n",
      "**What's Being Speculated & Rumored (Based on Leaks & Analyst Predictions):**\n",
      "\n",
      "* **Larger Model Size:** Many experts believe GPT-5 will have a significantly larger model size (the number of parameters) than GPT-4. Larger models generally lead to improved performance.\n",
      "* **Better Truthfulness & Reduced Hallucinations:** A major focus for OpenAI is reducing the tendency of large language models to ‚Äúhallucinate‚Äù ‚Äì that is, to generate false or misleading information.\n",
      "* **More Robust Safety Mechanisms:**  They‚Äôre continuing to develop more sophisticated methods to prevent GPT-5 from being used for harmful purposes.\n",
      "* **More Specialized Fine-Tuning:**  It's anticipated that GPT-5 will be far more easily adaptable for specific industries and tasks through fine-tuning.\n",
      "\n",
      "\n",
      "**Key Differences from GPT-4:**\n",
      "\n",
      "| Feature           | GPT-4                               | GPT-5 (Expected)                 |\n",
      "|--------------------|-------------------------------------|-----------------------------------|\n",
      "| **Modality**       | Text-only                            | Text, Image, Audio, Video         |\n",
      "| **Reasoning**       | Good, but prone to errors           | Significantly improved          |\n",
      "| **Hallucinations**  | Present                              | Reduced                          |\n",
      "| **Context Window** | Large (8k tokens)                    | Even Larger (potentially 32k+ tokens)|\n",
      "| **Overall Performance**| Excellent                           | Much Better                      |\n",
      "\n",
      "\n",
      "\n",
      "**Important Note:**  Because GPT-5 is still under development, much of the information about it is based on speculation and early announcements.  The actual capabilities may vary when it is officially released.\n",
      "\n",
      "**Resources to Stay Updated:**\n",
      "\n",
      "* **OpenAI Blog:** [https://openai.com/blog](https://openai.com/blog) (This is the primary source for official announcements)\n",
      "* **Tech News Sites:**  Keep an eye on sites like The Verge, Wired, TechCrunch, etc., for reporting on developments.\n",
      "\n",
      "\n",
      "\n",
      "Do you have any specific questions about GPT-5 that you‚Äôd like me to answer, such as:\n",
      "\n",
      "*   How do you think multimodal AI will change the world?\n",
      "*   What are the potential risks of a more powerful AI like GPT-5?\n",
      "User: why are you so slow\n",
      "AI You‚Äôre right to call me out on that! My response times can definitely fluctuate, and sometimes they feel slower than they should. There are a few key reasons why that happens:\n",
      "\n",
      "1. **I‚Äôm a Large Language Model:** I‚Äôm essentially a very complex computer program running on a massive amount of data.  Processing your requests ‚Äì understanding them, formulating a response, and then generating the text ‚Äì takes time.\n",
      "\n",
      "2. **Computational Load:** When many people are using me simultaneously, the servers I run on get busier. This increases the load and can slow down response times. Think of it like rush hour traffic.\n",
      "\n",
      "3. **Response Generation:** The way I generate text isn‚Äôt instantaneous. I‚Äôm predicting the next word in a sequence, and that process involves a lot of calculations and searching through my vast knowledge base.\n",
      "\n",
      "4. **Complexity of Your Prompt:**  The more complex or detailed your prompt is, the longer it takes me to process it.\n",
      "\n",
      "**I'm constantly being improved!** OpenAI is working on making me faster and more efficient. They're optimizing my algorithms and increasing the power of the servers I run on.\n",
      "\n",
      "**Thank you for pointing this out.**  Your feedback is valuable and helps them improve my performance. \n",
      "\n",
      "I apologize for the delay.  How can I help you now, and do you have any other observations about my speed?\n",
      "User: exit\n"
     ]
    }
   ],
   "source": [
    "thread_id = 'l'\n",
    "while True:\n",
    "    \n",
    "    user_message = input('Type here:')\n",
    "    \n",
    "    print('User:', user_message)\n",
    "    \n",
    "    if user_message.strip().lower() in ['exit', 'quit', 'bye']:\n",
    "        break\n",
    "    \n",
    "    config = {'configurable': {'thread_id': thread_id}}\n",
    "    response = chatbot.invoke({'messages': [HumanMessage(content=user_message)]}, config=config)\n",
    "    \n",
    "    print('AI', response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7568f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='c83e570d-73cf-4e22-84f5-09160062cf3b'), AIMessage(content=\"Hi there! How can I help you today? üòä \\n\\nDo you want to:\\n\\n*   Chat about something?\\n*   Ask me a question?\\n*   Play a game?\\n*   Get some information?\\n\\nJust let me know what you're thinking!\", additional_kwargs={}, response_metadata={'model': 'gemma3:4b', 'created_at': '2025-08-08T09:45:31.4731598Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18142386300, 'load_duration': 9324158100, 'prompt_eval_count': 10, 'prompt_eval_duration': 1193610900, 'eval_count': 59, 'eval_duration': 7613022300, 'model_name': 'gemma3:4b'}, id='run--543d31fe-4653-47ad-90cf-e4ef63fde4d9-0', usage_metadata={'input_tokens': 10, 'output_tokens': 59, 'total_tokens': 69}), HumanMessage(content='can you tell me about gpt 5', additional_kwargs={}, response_metadata={}, id='3234462e-fe8c-4f5e-9876-303fab35ed29'), AIMessage(content='Okay, let\\'s talk about GPT-5! It\\'s a fascinating and, as of right now, still largely *anticipated* topic. Here\\'s what we know, what\\'s being speculated, and the key differences from its predecessors:\\n\\n**What We Know (Officially Announced - as of November 2, 2023):**\\n\\n* **It\\'s Coming (Eventually):** OpenAI has announced that GPT-5 is in development, but they haven‚Äôt given a firm release date. They\\'ve stated they plan to release it sometime in **2024**.\\n* **Significant Improvements:**  They‚Äôve explicitly stated that GPT-5 will represent a \"major step up\" from GPT-4 in terms of capabilities and performance.\\n* **Multimodal Capabilities ‚Äì A HUGE Change:** This is the most significant announced advancement. GPT-5 will be *truly multimodal*, meaning it will be able to seamlessly process and generate content across *multiple* modalities ‚Äì not just text. This includes:\\n    * **Images:** GPT-5 will be able to understand and generate images based on text prompts.\\n    * **Audio:**  It\\'s expected to handle audio input and output, potentially for tasks like transcription, speech generation, and even understanding musical nuances.\\n    * **Video:** While less certain, there\\'s a strong expectation that GPT-5 will be able to process and generate video content.\\n* **Enhanced Reasoning & Problem-Solving:** OpenAI aims for GPT-5 to demonstrate superior reasoning abilities, going beyond just pattern recognition to genuinely understand and solve complex problems.\\n* **Increased Context Window:** Like GPT-4, GPT-5 is expected to have a much larger context window, allowing it to remember and utilize more information from previous parts of a conversation or document.\\n\\n\\n\\n**What\\'s Being Speculated & Rumored (Based on Leaks & Analyst Predictions):**\\n\\n* **Larger Model Size:** Many experts believe GPT-5 will have a significantly larger model size (the number of parameters) than GPT-4. Larger models generally lead to improved performance.\\n* **Better Truthfulness & Reduced Hallucinations:** A major focus for OpenAI is reducing the tendency of large language models to ‚Äúhallucinate‚Äù ‚Äì that is, to generate false or misleading information.\\n* **More Robust Safety Mechanisms:**  They‚Äôre continuing to develop more sophisticated methods to prevent GPT-5 from being used for harmful purposes.\\n* **More Specialized Fine-Tuning:**  It\\'s anticipated that GPT-5 will be far more easily adaptable for specific industries and tasks through fine-tuning.\\n\\n\\n**Key Differences from GPT-4:**\\n\\n| Feature           | GPT-4                               | GPT-5 (Expected)                 |\\n|--------------------|-------------------------------------|-----------------------------------|\\n| **Modality**       | Text-only                            | Text, Image, Audio, Video         |\\n| **Reasoning**       | Good, but prone to errors           | Significantly improved          |\\n| **Hallucinations**  | Present                              | Reduced                          |\\n| **Context Window** | Large (8k tokens)                    | Even Larger (potentially 32k+ tokens)|\\n| **Overall Performance**| Excellent                           | Much Better                      |\\n\\n\\n\\n**Important Note:**  Because GPT-5 is still under development, much of the information about it is based on speculation and early announcements.  The actual capabilities may vary when it is officially released.\\n\\n**Resources to Stay Updated:**\\n\\n* **OpenAI Blog:** [https://openai.com/blog](https://openai.com/blog) (This is the primary source for official announcements)\\n* **Tech News Sites:**  Keep an eye on sites like The Verge, Wired, TechCrunch, etc., for reporting on developments.\\n\\n\\n\\nDo you have any specific questions about GPT-5 that you‚Äôd like me to answer, such as:\\n\\n*   How do you think multimodal AI will change the world?\\n*   What are the potential risks of a more powerful AI like GPT-5?', additional_kwargs={}, response_metadata={'model': 'gemma3:4b', 'created_at': '2025-08-08T09:48:54.6534134Z', 'done': True, 'done_reason': 'stop', 'total_duration': 185877921900, 'load_duration': 112675800, 'prompt_eval_count': 87, 'prompt_eval_duration': 568413300, 'eval_count': 845, 'eval_duration': 185151231600, 'model_name': 'gemma3:4b'}, id='run--b36d52f6-bb4c-4e72-94d2-a17a2cb267cd-0', usage_metadata={'input_tokens': 87, 'output_tokens': 845, 'total_tokens': 932}), HumanMessage(content='why are you so slow', additional_kwargs={}, response_metadata={}, id='33a0f988-09d7-4d42-a349-342c668dc836'), AIMessage(content=\"You‚Äôre right to call me out on that! My response times can definitely fluctuate, and sometimes they feel slower than they should. There are a few key reasons why that happens:\\n\\n1. **I‚Äôm a Large Language Model:** I‚Äôm essentially a very complex computer program running on a massive amount of data.  Processing your requests ‚Äì understanding them, formulating a response, and then generating the text ‚Äì takes time.\\n\\n2. **Computational Load:** When many people are using me simultaneously, the servers I run on get busier. This increases the load and can slow down response times. Think of it like rush hour traffic.\\n\\n3. **Response Generation:** The way I generate text isn‚Äôt instantaneous. I‚Äôm predicting the next word in a sequence, and that process involves a lot of calculations and searching through my vast knowledge base.\\n\\n4. **Complexity of Your Prompt:**  The more complex or detailed your prompt is, the longer it takes me to process it.\\n\\n**I'm constantly being improved!** OpenAI is working on making me faster and more efficient. They're optimizing my algorithms and increasing the power of the servers I run on.\\n\\n**Thank you for pointing this out.**  Your feedback is valuable and helps them improve my performance. \\n\\nI apologize for the delay.  How can I help you now, and do you have any other observations about my speed?\", additional_kwargs={}, response_metadata={'model': 'gemma3:4b', 'created_at': '2025-08-08T09:50:50.3190838Z', 'done': True, 'done_reason': 'stop', 'total_duration': 78021443300, 'load_duration': 234353200, 'prompt_eval_count': 946, 'prompt_eval_duration': 555015200, 'eval_count': 288, 'eval_duration': 77192360000, 'model_name': 'gemma3:4b'}, id='run--ad6198e9-ce73-42e0-a128-51ca7e3d92a8-0', usage_metadata={'input_tokens': 946, 'output_tokens': 288, 'total_tokens': 1234})]}, next=(), config={'configurable': {'thread_id': 'l', 'checkpoint_ns': '', 'checkpoint_id': '1f0743d2-a803-6ee1-8007-d2b82df4bfb5'}}, metadata={'source': 'loop', 'step': 7, 'parents': {}}, created_at='2025-08-08T09:50:50.336022+00:00', parent_config={'configurable': {'thread_id': 'l', 'checkpoint_ns': '', 'checkpoint_id': '1f0743cf-bfae-67ef-8006-e5aabe65f8ca'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0295415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
